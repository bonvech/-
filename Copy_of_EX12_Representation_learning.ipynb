{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bonvech/-/blob/master/Copy_of_EX12_Representation_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7FVEyM2ATk"
      },
      "source": [
        "# –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–≤"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVsRWof9kTWs",
        "outputId": "70f681e7-2e2b-40a6-d508-cbdfa13ba626"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m802.3/802.3 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eZMTlqGx2ATn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from warnings import simplefilter\n",
        "\n",
        "simplefilter(\"ignore\", UserWarning)\n",
        "simplefilter(\"ignore\", RuntimeWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fHWUBr52ATo"
      },
      "outputs": [],
      "source": [
        "def plot_manifold(latent_r, labels=None, alpha=0.9, classes=None, title=None):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    if labels is None:\n",
        "        plt.scatter(latent_r[:, 0], latent_r[:, 1], alpha=alpha)\n",
        "    else:\n",
        "        plt.scatter(latent_r[:, 0], latent_r[:, 1], c=labels, cmap=\"tab10\", alpha=alpha)\n",
        "        cbar = plt.colorbar()\n",
        "    if classes:\n",
        "        num_of_classes = list(range(0, len(classes)))\n",
        "        cbar.ax.set_yticks(num_of_classes)\n",
        "        cbar.ax.set_yticklabels(classes)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# plotting reconstructed and noised images\n",
        "def plot_samples(*args, digit_size=28, name=None, single_size=2):\n",
        "    args = [x.squeeze() for x in args]\n",
        "    n = min([x.shape[0] for x in args])\n",
        "    figure = np.zeros((digit_size * len(args), digit_size * n))\n",
        "\n",
        "    for i in range(n):\n",
        "        for j in range(len(args)):\n",
        "            figure[\n",
        "                j * digit_size : (j + 1) * digit_size,\n",
        "                i * digit_size : (i + 1) * digit_size,\n",
        "            ] = args[j][i].squeeze()\n",
        "\n",
        "    plt.figure(figsize=(single_size * n, single_size * len(args)))\n",
        "\n",
        "    plt.imshow(figure, cmap=\"gray_r\", clim=(0, 1))\n",
        "\n",
        "    plt.grid(False)\n",
        "    ax = plt.gca()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    if name is not None:\n",
        "        plt.savefig(name)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKITefMs2ATp"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        hidden_dims = [32, 64, 128, 256]  # num of filters in layers\n",
        "        modules = []\n",
        "        in_channels = 1  # initial value of channels\n",
        "        for h_dim in hidden_dims:  # conv layers\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,  # num of input channels\n",
        "                        out_channels=h_dim,  # num of output channels\n",
        "                        kernel_size=3,\n",
        "                        stride=2,  # convolution kernel step\n",
        "                        padding=1,  # save shape\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(h_dim),\n",
        "                    nn.LeakyReLU(),\n",
        "                )\n",
        "            )\n",
        "            in_channels = h_dim  # changing number of input channels for next iteration\n",
        "\n",
        "        modules.append(nn.Flatten())  # to vector, size 256 * 2 * 2 = 1024\n",
        "        modules.append(nn.Linear(256 * 2 * 2, latent_dim))\n",
        "\n",
        "        self.encoder = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        hidden_dims = [256, 128, 64, 32]  # num of filters in layers\n",
        "        self.linear = nn.Linear(in_features=latent_dim, out_features=1024)\n",
        "\n",
        "        modules = []\n",
        "        for i in range(len(hidden_dims) - 1):  # define upsample layers\n",
        "            modules.append(\n",
        "                nn.Sequential(\n",
        "                    nn.Upsample(scale_factor=2),\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=hidden_dims[i],\n",
        "                        out_channels=hidden_dims[i + 1],\n",
        "                        kernel_size=3,\n",
        "                        padding=1,\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(hidden_dims[i + 1]),\n",
        "                    nn.LeakyReLU(),\n",
        "                )\n",
        "            )\n",
        "\n",
        "        modules.append(\n",
        "            nn.Sequential(\n",
        "                nn.Upsample(scale_factor=2),\n",
        "                nn.Conv2d(in_channels=hidden_dims[-1], out_channels=1, kernel_size=5),\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(*modules)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)  # from latents space to Linear\n",
        "        x = x.view(-1, 256, 2, 2)  # reshape\n",
        "        x = self.decoder(x)  # reconstruction\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3wsP06D2ATp"
      },
      "outputs": [],
      "source": [
        "class LitAE(L.LightningModule):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def forward_handler(self, data, *args, **kwargs):\n",
        "        # here is the logic how data is moved through AE\n",
        "        latent = self.encoder(data)\n",
        "        recon = self.decoder(latent)\n",
        "        return latent, recon\n",
        "\n",
        "    def loss_handler(self, recon, data, *args, **kwargs):\n",
        "        # here is the loss function computing\n",
        "        loss = F.mse_loss(F.sigmoid(recon), data)\n",
        "        return loss\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "\n",
        "        latent, recon = self.forward_handler(data, labels)\n",
        "        loss = self.loss_handler(recon, data, latent)\n",
        "\n",
        "        self.log(\"train_loss\", loss, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "\n",
        "        latent, recon = self.forward_handler(data, labels)\n",
        "        loss = self.loss_handler(recon, data, latent)\n",
        "\n",
        "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
        "        return loss\n",
        "\n",
        "    def on_test_epoch_start(self):\n",
        "        # create dict with empty tensors for further accumulating over batches\n",
        "        self.test_result = defaultdict(torch.Tensor)\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        data, labels = batch\n",
        "\n",
        "        latent, recon = self.forward_handler(data, labels)\n",
        "        recon = F.sigmoid(recon)\n",
        "        self.update_test_result(data, recon, latent, labels)\n",
        "\n",
        "    def update_test_result(self, data, recon, latent, labels):\n",
        "        # accumulating results every batch\n",
        "        self.test_result[\"real\"] = torch.cat([self.test_result[\"real\"], data.cpu()])\n",
        "        self.test_result[\"recon\"] = torch.cat([self.test_result[\"recon\"], recon.cpu()])\n",
        "        self.test_result[\"latent\"] = torch.cat(\n",
        "            [self.test_result[\"latent\"], latent.cpu()]\n",
        "        )\n",
        "        self.test_result[\"labels\"] = torch.cat(\n",
        "            [self.test_result[\"labels\"], labels.cpu()]\n",
        "        )\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # simply change type from torch tensor to numpy array\n",
        "        # for every item in test_result dictionary\n",
        "        for key in self.test_result:\n",
        "            self.test_result[key] = self.test_result[key].numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uhyDZYe2ATq"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 1. –ê–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥–ª—è FashionMNIST c SSIM loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dw-wocjn2ATq"
      },
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ FashionMNIST.\n",
        "\n",
        "* –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —ç–Ω–∫–æ–¥–µ—Ä –∏ –¥–µ–∫–æ–¥–µ—Ä –∏–∑ –ª–µ–∫—Ü–∏–∏ (–∫–æ–¥ `Encoder`, `Decoder` –≤—ã—à–µ).\n",
        "* –ó–∞–º–µ–Ω–∏—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –Ω–∞ `SSIM loss` [üìö[wiki]](https://ru.wikipedia.org/wiki/SSIM).\n",
        "* –û–±—É—á–∏—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä —Å —Ä–∞–∑–º–µ—Ä–æ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è 2.\n",
        "* –í—ã–≤–µ–¥–∏—Ç–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ, —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è –ª–∏ –≤ –Ω–µ–º –∫–ª–∞—Å—Å—ã?\n",
        "\n",
        "–î–∞–ª–µ–µ:\n",
        "\n",
        "* –û–±—É—á–∏—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä —Å —Ä–∞–∑–º–µ—Ä–æ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è 30.\n",
        "* –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.\n",
        "\n",
        "–ù–∞–ø–∏—à–∏—Ç–µ –≤—ã–≤–æ–¥—ã."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRXR7uuF2ATq"
      },
      "source": [
        "**–ü–æ–¥—Å–∫–∞–∑–∫–∏:**\n",
        "\n",
        "* –î–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å Lightning-–º–æ–¥—É–ª–µ–º `LitAE` (–∫–æ–¥ –≤—ã—à–µ). –î–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –∑–∞–º–µ–Ω–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –æ—Ç–Ω–∞—Å–ª–µ–¥–æ–≤–∞—Ç—å—Å—è –æ—Ç `LitAE` –∏ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –º–µ—Ç–æ–¥ `loss_handler`, –∑–∞–º–µ–Ω–∏–≤ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å –≤ –Ω–µ–º.\n",
        "* –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `plot_manifold` (–∫–æ–¥ –≤—ã—à–µ).\n",
        "* –î–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –∏—Ö —Ä–µ–∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–π —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `plot_samples` (–∫–æ–¥ –≤—ã—à–µ)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyemPoff2ATr"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6Xpz9X62ATr"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import lightning as L\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision.datasets import FashionMNIST\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6GIalte2ATr"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eenu0a6B2ATs"
      },
      "outputs": [],
      "source": [
        "root = \"./data\"\n",
        "\n",
        "train_set = FashionMNIST(\n",
        "    root=root, train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "test_set = FashionMNIST(\n",
        "    root=root, train=False, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_set, val_set = random_split(train_set, lengths=[50000, 10000])\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=batch_size, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_set, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=batch_size, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2O4RUxs2ATs"
      },
      "source": [
        "–í –¥–∞—Ç–∞—Å–µ—Ç–µ 10 –∫–ª–∞—Å—Å–æ–≤, –∫–∞–∂–¥—ã–π —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–¥–Ω–æ–º—É –∏–∑ –ø—Ä–µ–¥–º–µ—Ç–æ–≤ –≥–∞—Ä–¥–µ—Ä–æ–±–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEo0Yy1-2ATs"
      },
      "outputs": [],
      "source": [
        "# Method for display all class samples from dataset\n",
        "\n",
        "\n",
        "def show_dataset(dataset):\n",
        "    fig, axs = plt.subplots(1, len(dataset.classes), figsize=(20, 5))\n",
        "    for cls_num, name in enumerate(dataset.classes):\n",
        "        i = np.argwhere(dataset.targets == cls_num)[0][0]\n",
        "        ax = axs[cls_num]\n",
        "        ax.imshow(dataset.data[i], cmap=\"gray_r\")\n",
        "        ax.set_title(name)\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZfqFL5C2ATt"
      },
      "outputs": [],
      "source": [
        "show_dataset(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5y6SdI7U2ATt"
      },
      "source": [
        "–ó–∞–¥–∞–π—Ç–µ `latent_dim` —Ä–∞–≤–Ω—ã–º 2 –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –ª–∞—Ç–µ–Ω—Ç–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –º–æ–¥–µ–ª–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏ –¥–µ–∫–æ–¥–µ—Ä–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKmwfX5W2ATt"
      },
      "outputs": [],
      "source": [
        "L.seed_everything(42)\n",
        "\n",
        "latent_dim =   # Your code here\n",
        "encoder =  # Your code here\n",
        "decoder =  # Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OOzyEcB2ATt"
      },
      "source": [
        "–û–ø–∏—à–∏—Ç–µ –∫–ª–∞—Å—Å-–Ω–∞—Å–ª–µ–¥–Ω–∏–∫ `LitAE`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `SSIM loss` [üìö[wiki]](https://ru.wikipedia.org/wiki/SSIM) –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ –≤–Ω—É—Ç—Ä–∏ `loss_handler`. –ú–æ–∂–Ω–æ –≤–æ—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≥–æ—Ç–æ–≤–æ–π [—Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π üêæ[git]](https://github.com/VainF/pytorch-msssim):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f16WfgwK2ATt"
      },
      "outputs": [],
      "source": [
        "class LitAE_with_SSIM(LitAE):\n",
        "    def loss_handler(self, recon, data, *args, **kwargs):\n",
        "        # Your code here\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FrXd4-L2ATt"
      },
      "source": [
        "–ù–∞–∫–æ–Ω–µ—Ü, –æ–±—É—á–∏—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfEXMjfH2ATu"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvkLbLX22ATu"
      },
      "source": [
        "–î–ª—è –ø—Ä–æ–≥–æ–Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –≤–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å `trainer.test`. –†–µ–∑—É–ª—å—Ç–∞—Ç —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±—É–¥–µ—Ç –∑–∞–ø–∏—Å–∞–Ω –≤ —Å–ª–æ–≤–∞—Ä—å –≤ –∞—Ç—Ä–∏–±—É—Ç–µ `.test_result` Lightning-–º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCc8A7Ws2ATu"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbvnZjjo2ATu"
      },
      "source": [
        "–í—ã–≤–µ–¥–∏—Ç–µ –ª–∞—Ç–µ–Ω—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±—ä–µ–∫—Ç–æ–≤ –Ω–∞ –ø–ª–æ—Å–∫–æ—Å—Ç–∏. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ, —Ä–∞–∑–¥–µ–ª—è—é—Ç—Å—è –ª–∏ –≤ –Ω–µ–º –∫–ª–∞—Å—Å—ã? –ö–∞–∫–∏–µ –∫–ª–∞—Å—Å—ã —Å–º–µ—à–∏–≤–∞—é—Ç—Å—è, –∞ –∫–∞–∫–∏–µ —Ö–æ—Ä–æ—à–æ –æ—Ç–¥–µ–ª—è—é—Ç—Å—è?\n",
        "\n",
        "–£ —Ñ—É–Ω–∫—Ü–∏–∏ `plot_manifold` –µ—Å—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç `classes`. –í –Ω–µ–≥–æ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ (`test_set.classes`) –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π –≤–º–µ—Å—Ç–æ –Ω–æ–º–µ—Ä–æ–≤ –∫–ª–∞—Å—Å–æ–≤."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfWEGwS82ATu"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsFywqs12ATu"
      },
      "source": [
        "*–í–∞—à–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è:*\n",
        "\n",
        "***Your text here***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnMFWwqk2ATu"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –æ–±—É—á–∏—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä —Å —Ä–∞–∑–º–µ—Ä–æ–º –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ —Å–ª–æ—è 30."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Swhcw922ATv"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xtu0MEDq2ATv"
      },
      "source": [
        "–û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ. –ü—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–π—Ç–µ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã—Ö –µ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é `plot_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMnPgOco2ATv"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKw7mqIo2ATv"
      },
      "source": [
        "–ö–∞–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –≤ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –≤—ã –º–æ–∂–µ—Ç–µ –æ—Ç–º–µ—Ç–∏—Ç—å?\n",
        "\n",
        "*–í–∞—à–∏ –Ω–∞–±–ª—é–¥–µ–Ω–∏—è:*\n",
        "\n",
        "***Your text here***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGE0_krH2ATv"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqmANHll2ATv"
      },
      "source": [
        "1. –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –ª–∞—Ç–µ–Ω—Ç–Ω–æ–≥–æ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–∞ –¥–ª—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞ —Å `latent_dim=2`, **–≤—ã–≤–æ–¥—ã**. –ü—Ä–∏–º–µ—Ä –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:\n",
        "\n",
        "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/result_1_1_task_ex12.png\" width=\"500\"/>\n",
        "\n",
        "\n",
        "2. –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º c `latent_dim=30`, **–≤—ã–≤–æ–¥—ã**. –ü—Ä–∏–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:\n",
        "\n",
        "<img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/result_2_1_task_ex12.png\" width=\"500\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fYKVaeA2ATv"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 2. –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª–∏–π —Å –ø–æ–º–æ—â—å—é –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FT8yP5j2ATw"
      },
      "source": [
        "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º —Å–ª–µ–¥—É—é—â—É—é —Å–∏—Ç—É–∞—Ü–∏—é: –Ω–∞–º –Ω—É–∂–Ω–∞ —Å–∏—Å—Ç–µ–º–∞, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑–∞. –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —è–≤–ª—è–µ—Ç—Å—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑–∞, —Ç–æ —Å–∏—Å—Ç–µ–º–∞ –¥–æ–ª–∂–Ω–∞ —Å–æ–æ–±—â–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –æ–± –æ—à–∏–±–∫–µ –∏ –Ω–µ –ø—Ä–∏–Ω–∏–º–∞—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\n",
        "\n",
        "–ò–¥–µ—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Å–ª–µ–¥—É—é—â–µ–º: –µ—Å–ª–∏ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –º–æ–∂–µ—Ç –≤—ã—É—á–∏—Ç—å –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑–∞, —Ç–æ –ø—Ä–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ —è–≤–ª—è—é—Ç—Å—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–µ–π —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑–∞, –æ—à–∏–±–∫–∞ –±—É–¥–µ—Ç —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –±–æ–ª—å—à–µ. –£—Å—Ç–∞–Ω–æ–≤–∏–≤ –ø–æ—Ä–æ–≥ —ç—Ç–æ–π –æ—à–∏–±–∫–∏, –º—ã —Å–º–æ–∂–µ–º –æ—Ç–¥–µ–ª—è—Ç—å –Ω—É–∂–Ω—ã–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –æ—Ç –Ω–µ–Ω—É–∂–Ω—ã—Ö.\n",
        "\n",
        "* –û–±—É—á–∏—Ç–µ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è—Ö —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑–∞ (RetinaMNIST).\n",
        "* –ü–æ–¥–∞–π—Ç–µ –≤ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –¥—Ä—É–≥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–∑–¥–µ—Å—å –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω BloodMNIST).\n",
        "* –ü–æ—Å—á–∏—Ç–∞–π—Ç–µ –æ—à–∏–±–∫—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤.\n",
        "* –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–æ—Ä–æ–≥ (–∑–Ω–∞—á–µ–Ω–∏–µ –æ—à–∏–±–∫–∏) –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∫–ª–∞—Å—Å–∞ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ (—Å–µ—Ç—á–∞—Ç–∫–∞ –≥–ª–∞–∑–∞ –∏–ª–∏ –Ω–µ—Ç).\n",
        "* –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç–µ—Å—Ç—ã.\n",
        "* –ù–∞–ø–∏—à–∏—Ç–µ –≤—ã–≤–æ–¥—ã."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MmqBBTZ2ATw"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u4qN2Kig2ATw"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade git+https://github.com/MedMNIST/MedMNIST.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEUN2S6u2ATw"
      },
      "outputs": [],
      "source": [
        "import medmnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightning as L\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from medmnist import INFO\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import PrecisionRecallDisplay\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGSghZqD2ATw"
      },
      "source": [
        "[[doc] üõ†Ô∏è MedMNIST](https://medmnist.com/) ‚Äî —ç—Ç–æ –Ω–∞–±–æ—Ä –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤, –ø–æ —Ñ–æ—Ä–º–∞—Ç—É –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö MNIST:\n",
        "\n",
        "* —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π 28√ó28,\n",
        "* —Å–æ–≤–º–µ—Å—Ç–∏–º—ã —Å PyTorch ([–ø—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—èüêæ[git]](https://github.com/MedMNIST/MedMNIST/blob/main/examples/getting_started.ipynb))."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBR9V09X2ATx"
      },
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ –±—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å —Å –¥–≤—É–º—è –¥–∞—Ç–∞—Å–µ—Ç–∞–º–∏: RetinaMNIST –∏ BloodMNIST.\n",
        "\n",
        "–ü–µ—Ä–≤—ã–π —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–µ—Ç—á–∞—Ç–∫–∏ –≥–ª–∞–∑, –≤—Ç–æ—Ä–æ–π ‚Äî –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed_maIZ-2ATx"
      },
      "outputs": [],
      "source": [
        "import medmnist\n",
        "from medmnist import INFO\n",
        "\n",
        "DataClass = getattr(medmnist, INFO[\"retinamnist\"][\"python_class\"])\n",
        "\n",
        "train_retina_dataset = DataClass(split=\"train\", download=True)\n",
        "val_retina_dataset = DataClass(split=\"val\", download=True)\n",
        "\n",
        "plt.imshow(val_retina_dataset[0][0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj2KkBdS2ATy"
      },
      "source": [
        "–ù–µ—Å–º–æ—Ç—Ä—è –Ω–∞ –∑–∞—è–≤–ª–µ–Ω–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å PyTorch, —É –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –Ω–µ—Ç —Å–≤–æ–π—Å—Ç–≤ `targets` –∏ `data`.\n",
        "\n",
        "–ù–æ –µ—Å—Ç—å —Å–ª–æ–≤–∞—Ä—å `info` ([–∫–æ–¥ üêæ[git]](https://github.com/MedMNIST/MedMNIST/blob/main/medmnist/dataset.py))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6aMHDLr2ATy"
      },
      "outputs": [],
      "source": [
        "info = val_retina_dataset.info\n",
        "info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eu7ubCaQ2ATy"
      },
      "source": [
        "–í –Ω–µ–º –µ—Å—Ç—å –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ–µ `targets` —Å–≤–æ–π—Å—Ç–≤–æ `labels`, –∞ —É —Å–∞–º–æ–≥–æ –æ–±—ä–µ–∫—Ç–∞ –µ—Å—Ç—å –º–∞—Å—Å–∏–≤ `imgs`, –∞–Ω–∞–ª–æ–≥–∏—á–Ω—ã–π `data` –≤ torchvision –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huBEEcXw2ATy"
      },
      "outputs": [],
      "source": [
        "print(\"labels\", val_retina_dataset.labels.shape)\n",
        "print(\"images\", val_retina_dataset.imgs.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKerROIW2ATy"
      },
      "source": [
        "–ò—Å–ø–æ–ª—å–∑—É—è —ç—Ç–∏ —Å–≤–æ–π—Å—Ç–≤–∞, –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º —Å –Ω–∞—à–∏–º –∫–æ–¥–æ–º, –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–º –¥–ª—è MNIST:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dJvmZ3v52ATy"
      },
      "outputs": [],
      "source": [
        "def cast2torch(ds):\n",
        "    ds.targets = ds.labels\n",
        "    ds.data = ds.imgs\n",
        "    ds.classes = list(info[\"label\"].values())\n",
        "\n",
        "\n",
        "cast2torch(val_retina_dataset)\n",
        "cast2torch(train_retina_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGh102Il2ATz"
      },
      "source": [
        "**RetinaMNIST classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXs0e1bv2ATz"
      },
      "outputs": [],
      "source": [
        "show_dataset(val_retina_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzCmaUHK2ATz"
      },
      "source": [
        "–ù–∞–∑–≤–∞–Ω–∏–π –∫–ª–∞—Å—Å–æ–≤ —Ç—É—Ç –Ω–µ—Ç, –Ω–æ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏ –æ–Ω–∏ –Ω–∞–º –∏ –Ω–µ –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è.\n",
        "–¢–µ–ø–µ—Ä—å –∑–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç —Å –∫–ª–µ—Ç–∫–∞–º–∏ –∫—Ä–æ–≤–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2w7BdZd72ATz"
      },
      "outputs": [],
      "source": [
        "DataClass = getattr(medmnist, INFO[\"bloodmnist\"][\"python_class\"])\n",
        "test_blood_dataset = DataClass(split=\"test\", download=True)\n",
        "cast2torch(test_blood_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BloodMNIST classes**"
      ],
      "metadata": {
        "id": "EheGYACmcAkr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN_5ndHF2ATz"
      },
      "outputs": [],
      "source": [
        "show_dataset(test_blood_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmYIrvOc2ATz"
      },
      "source": [
        "–ü–æ —Ñ–æ—Ä–º–µ –∫–ª–µ—Ç–∫–∏ –∫—Ä–æ–≤–∏ –æ—Ç–¥–∞–ª–µ–Ω–Ω–æ –Ω–∞–ø–æ–º–∏–Ω–∞—é—Ç —Ñ–æ—Ç–æ —Å–µ—Ç—á–∞—Ç–∫–∏.\n",
        "\n",
        "–ü—Ä–µ–¥—Å—Ç–∞–≤–∏–º, —á—Ç–æ –ø—Ä–∏ —Å–±–æ—Ä–µ –Ω–æ–≤–æ–π –ø–æ—Ä—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏ –ø–æ –æ—à–∏–±–∫–µ –ø–æ–ø–∞–ª–∏ –≤ –ø–∞–ø–∫—É —Å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è–º–∏ —Å–µ—Ç—á–∞—Ç–∫–∏ –∏ –±—ã–ª–∏ –≤–∫–ª—é—á–µ–Ω—ã –≤ –Ω–æ–≤—É—é –≤–µ—Ä—Å–∏—é –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
        "\n",
        "–ù–∞–º –Ω–∞–¥–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫—É –∏ –æ—Ç–¥–µ–ª–∏—Ç—å —Ñ–æ—Ç–æ –∫–ª–µ—Ç–æ–∫ —Å–µ—Ç—á–∞—Ç–∫–∏ –æ—Ç —Ñ–æ—Ç–æ –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏.\n",
        "\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –æ–±—É—á–∏–º –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ —Ç–æ–π —á–∞—Å—Ç–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞, –∫–æ—Ç–æ—Ä–∞—è –±—ã–ª–∞ —Å–æ–±—Ä–∞–Ω–∞ —Ä–∞–Ω—å—à–µ –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—à–∏–±–æ–∫. –ë—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å, —á—Ç–æ —ç—Ç–æ `train_retina_dataset`.\n",
        "\n",
        "–û–±—É—á–∏–º –Ω–∞ –Ω–∏—Ö –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä. –î–ª—è —ç—Ç–æ–≥–æ —Å–æ–∑–¥–∞–¥–∏–º –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –∏ –¥–æ–±–∞–≤–∏–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –∫ –¥–∞—Ç–∞—Å–µ—Ç–∞–º. –í —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, —Å–¥–µ–ª–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–Ω–æ-–±–µ–ª—ã–º–∏, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–∞–π–ø–ª–∞–π–Ω –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ –∑–∞–¥–∞–Ω–∏—è."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmIUBkFi2AT0"
      },
      "outputs": [],
      "source": [
        "data_transform = transforms.Compose(\n",
        "    [\n",
        "        # Convert all images to Grayscale for sake of MNIST compatibility\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "train_retina_dataset.transform = data_transform\n",
        "val_retina_dataset.transform = data_transform\n",
        "test_blood_dataset.transform = data_transform\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = DataLoader(\n",
        "    train_retina_dataset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "val_loader = DataLoader(val_retina_dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "blood_loader = DataLoader(\n",
        "    test_blood_dataset, batch_size=1, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umEeH5iF2AT0"
      },
      "source": [
        "–°–æ–∑–¥–∞–π—Ç–µ —ç–Ω–∫–æ–¥–µ—Ä –∏ –¥–µ–∫–æ–¥–µ—Ä (`latent_dim=2`) –∏ –æ–±—É—á–∏—Ç–µ AE 15‚Äì30 —ç–ø–æ—Ö (–∑–∞–Ω–∏–º–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–µ–∫—É–Ω–¥).\n",
        "\n",
        "–ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `LitAE`, –≤ –∫–æ—Ç–æ—Ä–æ–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è MSE, –∏–ª–∏ `LitAE_with_SSIM`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ek-JIIS52AT0"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8EhZvLX2AT0"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞—É—á–∏–ª—Å—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å–µ—Ç—á–∞—Ç–∫–∏, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –µ–≥–æ —É—á–∏–ª–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYRHHGuW2AT0"
      },
      "outputs": [],
      "source": [
        "def get_mse_and_show_results(dataloader):\n",
        "    trainer.test(autoencoder, dataloader)\n",
        "    run_res = autoencoder.test_result\n",
        "\n",
        "    real = run_res[\"real\"]\n",
        "    recon = run_res[\"recon\"]\n",
        "\n",
        "    cnt = len(real)\n",
        "    mse = mean_squared_error(\n",
        "        real.reshape(cnt, -1), recon.reshape(cnt, -1), multioutput=\"raw_values\"\n",
        "    )\n",
        "\n",
        "    plot_samples(real[0:5], recon[0:5])\n",
        "    return mse\n",
        "\n",
        "\n",
        "mse_retina = get_mse_and_show_results(val_loader)\n",
        "print(\"MSE for correct retina images\", mse_retina.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn_UrHko2AT1"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –±—É–¥–µ—Ç, –µ—Å–ª–∏ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫–ª–µ—Ç–æ–∫ –∫—Ä–æ–≤–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE7vgnCJ2AT1"
      },
      "outputs": [],
      "source": [
        "mse_blood = get_mse_and_show_results(blood_loader)\n",
        "print(\"MSE for blood cell images\", mse_blood.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtQyqG6F2AT1"
      },
      "source": [
        "–í–∏–¥–Ω–æ, —á—Ç–æ –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –ø—ã—Ç–∞–µ—Ç—Å—è –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ —Å–µ—Ç—á–∞—Ç–∫–∏ –∏ –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ—Ä—è–¥–æ–∫ –±–æ–ª—å—à–µ. –ú–æ–∂–Ω–æ —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—é –æ—à–∏–±–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ \"–∏—Å–ø–æ—Ä—á–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\" –≤–æ–∑—å–º–µ–º `val` —á–∞c—Ç—å –∏–∑ RetinaMnist –∏ `test` —á–∞—Å—Ç—å –∏–∑ BloodMnist.\n",
        "\n",
        "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –æ—à–∏–±–æ–∫ `mse_retina` –∏ `mse_blood`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VWVZOvP2AT1"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDtW3XAU2AT1"
      },
      "source": [
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ—Ä–æ–≥ –æ—à–∏–±–∫–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ –≤—ã—á–∏—Å–ª–∏—Ç–µ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–¥–µ–ª–µ–Ω–∏—è —Å–Ω–∏–º–∫–æ–≤ —Å–µ—Ç—á–∞—Ç–∫–∏ –æ—Ç —Å–Ω–∏–º–∫–æ–≤ –∫—Ä–æ–≤–∏: accuracy, precision, recall, f1-score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X74CONam2AT1"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn7Hypz-2AT1"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQ_L6UaT2AT2"
      },
      "source": [
        "–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–¥–µ–ª–µ–Ω–∏—è —Å–Ω–∏–º–∫–æ–≤ —Å–µ—Ç—á–∞—Ç–∫–∏ –æ—Ç —Å–Ω–∏–º–∫–æ–≤ –∫—Ä–æ–≤–∏: accuracy, precision, recall, f1-score ‚Äî –Ω–µ –º–µ–Ω–µ–µ 0.95."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUjqiQIm2AT2"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 3. –ü–æ–∏—Å–∫ hard examples —Å –ø–æ–º–æ—â—å—é –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CUEmHU72AT2"
      },
      "source": [
        "–í —ç—Ç–æ–º –∑–∞–¥–∞–Ω–∏–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –Ω–∞–π—Ç–∏ —Å–∞–º—ã–µ \"–Ω–µ–∫—Ä–∞—Å–∏–≤—ã–µ\" —Ü–∏—Ñ—Ä—ã –≤ **–æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–µ** MNIST. –ù–∞–π–¥–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ü–∏—Ñ—Ä, –∫–æ—Ç–æ—Ä—ã–µ —Ö—É–∂–µ –≤—Å–µ–≥–æ –≤–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º.\n",
        "\n",
        "–û–¥–∏–Ω –∏–∑ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø–æ–¥—Ö–æ–¥–æ–≤:\n",
        "* –û–±—É—á–∏—Ç—å –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ MNIST.\n",
        "* –ü–æ—Å—á–∏—Ç–∞—Ç—å –æ—à–∏–±–∫—É –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏.\n",
        "* –û—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–ø–∏—Å–æ–∫ –æ—à–∏–±–æ–∫ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∏ –ø–æ–ª—É—á–∏—Ç—å –∏–Ω–¥–µ–∫—Å—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –æ—à–∏–±–∫–æ–π.\n",
        "* –û—Ç—Ä–∏—Å–æ–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.\n",
        "\n",
        "–í –∫–∞—á–µ—Å—Ç–≤–µ –∫—Ä–∏—Ç–µ—Ä–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —Ñ—É–Ω–∫—Ü–∏—é –ø–æ—Ç–µ—Ä—å, —Ç–∞–∫ –∏ –¥—Ä—É–≥–∏–µ –º–µ—Ä—ã —Å—Ö–æ–¥—Å—Ç–≤–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –Ω–∞–ø—Ä–∏–º–µ—Ä, [structural similarity index üõ†Ô∏è[doc]](https://scikit-image.org/docs/stable/auto_examples/transform/plot_ssim.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtMslGlF2AT2"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNlrG6Lf2AT2"
      },
      "source": [
        "–í—ã–≤–µ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏ —Å –Ω–∞–∏—Ö—É–¥—à–∏–º –∫–∞—á–µ—Å—Ç–≤–æ–º –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –∞–≤—Ç–æ—ç–Ω–∫–æ–¥–µ—Ä–æ–º.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGNHctoN2AT2"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/result_3_task_ex12.png\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jV8sHc-T2AT2"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7tiLncI2AT3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import lightning as L\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import transforms\n",
        "from collections import defaultdict\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXPeD4Fi2AT3"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0GrfazYm2AT3"
      },
      "outputs": [],
      "source": [
        "root = \"./data\"\n",
        "\n",
        "train_set = MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
        "torch.manual_seed(42)\n",
        "train_set, val_set = random_split(train_set, lengths=[50000, 10000])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXcEd5mk2AT3"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPHUEzSu2AT3"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 4. –ü–µ—Ä–µ–Ω–æ—Å —Å—Ç–∏–ª—è –ø—Ä–∏ –ø–æ–º–æ—â–∏ CVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctFqH9Ly2AT3"
      },
      "source": [
        "–° –ø–æ–º–æ—â—å—é CVAE –º–æ–∂–Ω–æ —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á—É –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç–∏–ª—è. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç–∏–ª—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ä–∞–∑–Ω—ã—Ö —Å–µ–º–µ—Ä–æ–∫ –Ω–∞ –¥—Ä—É–≥–∏–µ —Ü–∏—Ñ—Ä—ã:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4GiAIcx2AT3"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/style_transfer.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9H7SWqK2AT4"
      },
      "source": [
        "–í–∞—à–∞ –∑–∞–¥–∞—á–∞:\n",
        "- –û–±—É—á–∏—Ç–µ CVAE, –∫–∞–∫ –≤ –ª–µ–∫—Ü–∏–∏ (`latent_dim=2...10`). –í–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è —É—Å–ª–æ–≤–Ω—ã–π –¥–µ–∫–æ–¥–µ—Ä `CDecoder` –∏ `LitCVAE`.\n",
        "\n",
        "- –í–æ–∑—å–º–∏—Ç–µ 10 —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç—Ä–æ–µ–∫ –∏–∑ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —Ä–µ–∞–ª–∏–∑—É–π—Ç–µ –ø–µ—Ä–µ–Ω–æ—Å —Å—Ç–∏–ª—è —Ç—Ä–æ–µ–∫ –Ω–∞ –¥—Ä—É–≥–∏–µ —Ü–∏—Ñ—Ä—ã.\n",
        "\n",
        "- –í—ã–≤–µ–¥–∏—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é, –∫–∞–∫ –≤ –ø—Ä–∏–º–µ—Ä–µ. –ù–∞ –≤–∞—à–µ–π –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç—Ä–æ–π–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∏—Å—Ö–æ–¥–Ω—ã–µ, –∞ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ü–∏—Ñ—Ä—ã ‚Äî –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–µ—Ä–µ–Ω–æ—Å–∞ —Å—Ç–∏–ª—è."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJuA6sN82AT4"
      },
      "source": [
        "–ò–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7dvSKQ52AT4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import lightning as L\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from lightning.pytorch.loggers import TensorBoardLogger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAW2vL3X2AT4"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2BWCfKS2AT4"
      },
      "outputs": [],
      "source": [
        "root = \"./data\"\n",
        "\n",
        "train_set = MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_set = MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_set, val_set = random_split(train_set, lengths=[50000, 10000])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=64, shuffle=True, num_workers=2)\n",
        "\n",
        "val_loader = DataLoader(val_set, batch_size=64, shuffle=False, num_workers=2)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4sPzKfxo2AT4"
      },
      "outputs": [],
      "source": [
        "class VAEEncoder(Encoder):\n",
        "    def __init__(self, latent_dim):\n",
        "        if latent_dim % 2 != 0:  # check for the parity of the latent space\n",
        "            raise Exception(\"Latent size for VAEEncoder must be even\")\n",
        "\n",
        "        super().__init__(latent_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FecbxMsI2AT5"
      },
      "outputs": [],
      "source": [
        "class LitVAE(LitAE):\n",
        "    def __init__(self, encoder, decoder, kld_weight=0.005, recon_weight=1.0):\n",
        "        super().__init__(encoder, decoder)\n",
        "        self.kld_weight = kld_weight\n",
        "        self.recon_weight = recon_weight\n",
        "\n",
        "    def vae_split(self, latent):\n",
        "        size = (\n",
        "            latent.shape[1] // 2\n",
        "        )  # divide the latent representation into mu and log_var\n",
        "        mu = latent[:, :size]\n",
        "        log_var = latent[:, size:]\n",
        "        return mu, log_var\n",
        "\n",
        "    def vae_reparametrize(self, mu, log_var):\n",
        "        sigma = torch.exp(0.5 * log_var)\n",
        "        eps = torch.randn(mu.shape[0], mu.shape[1]).to(self.device)\n",
        "        return eps * sigma + mu\n",
        "\n",
        "    def kld_loss(self, mu, log_var):\n",
        "        var = log_var.exp()\n",
        "        kl_loss = torch.mean(-0.5 * torch.sum(log_var - var - mu**2 + 1, dim=1), dim=0)\n",
        "        return kl_loss\n",
        "\n",
        "    def forward_handler(self, data, *args, **kwargs):\n",
        "        # here is the logic how data is moved through AE\n",
        "        latent = self.encoder(data)\n",
        "\n",
        "        mu, log_var = self.vae_split(latent)\n",
        "        sample = self.vae_reparametrize(mu, log_var)\n",
        "\n",
        "        recon = self.decoder(sample)\n",
        "        return latent, recon\n",
        "\n",
        "    def loss_handler(self, recon, data, latent, *args, **kwargs):\n",
        "        mu, log_var = self.vae_split(latent)\n",
        "        # here is the loss function computing\n",
        "        loss = self.recon_weight * F.mse_loss(\n",
        "            F.sigmoid(recon), data\n",
        "        ) + self.kld_weight * self.kld_loss(mu, log_var)\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp7NUEmK2AT5"
      },
      "source": [
        "1. –í–æ—Å–ø–æ–ª—å–∑—É–π—Ç–µ—Å—å –∫–æ–¥–æ–º –¥–ª—è `CDecoder` –∏ `LitCVAE` –∏–∑ –ª–µ–∫—Ü–∏–∏, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å —Å–≤–æ–π CVAE. –í –∫–∞—á–µ—Å—Ç–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `VAEEncoder`. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–±—É—á–∞—Ç—å 5 —ç–ø–æ—Ö."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4swEWEY2AT5"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsGXfSRb2AT5"
      },
      "source": [
        "2. –û–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å –ø–æ–º–æ—â—å—é CVAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM_XFbRd2AT6"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm-vRiPX2AT6"
      },
      "source": [
        "3. –ò–∑ —Å–ª–æ–≤–∞—Ä—è, –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –æ—Ç–±–µ—Ä–∏—Ç–µ 10 —Å–ª—É—á–∞–π–Ω—ã—Ö —Ç—Ä–æ–µ–∫ (–≤–∞–º –ø–æ–º–æ–≥—É—Ç –∫–ª—é—á–∏ `\"labels\"` –∏ `\"real\"`). –í—ã–≤–µ–¥–∏—Ç–µ –∏—Ö —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `plot_samples`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOqrNPiK2AT6"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-dfUYrX2AT6"
      },
      "source": [
        "4. –¢–µ–ø–µ—Ä—å –≤–∞–º –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∞—à–∏ —Ç—Ä–æ–π–∫–∏ **—ç–Ω–∫–æ–¥–µ—Ä–æ–º** –∏ –ø–æ–ª—É—á–∏—Ç—å –¥–ª—è –Ω–∏—Ö –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, –∫–æ–¥–∏—Ä—É—é—â–∏–µ —Å—Ç–∏–ª—å –Ω–∞—á–µ—Ä—Ç–∞–Ω–∏—è. –î–∞–ª–µ–µ –≤ —Ü–∏–∫–ª–µ –ø–æ $i$ –æ—Ç 0 –¥–æ 9 –ø–æ–¥–∞—Ç—å –≤ –¥–µ–∫–æ–¥–µ—Ä –ª–∞—Ç–µ–Ω—Ç–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤–∞—à–∏—Ö —Ç—Ä–æ–µ–∫ –∏ –º–µ—Ç–∫—É $i$-—Ç–æ–π —Ü–∏—Ñ—Ä—ã.\n",
        "\n",
        "–ü–æ–¥—Å–∫–∞–∑–∫–∞: –≤–Ω–µ —Ü–∏–∫–ª–∞ —Å–æ–∑–¥–∞–π—Ç–µ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ `images`, –∞ –≤ —Ü–∏–∫–ª–µ –¥–æ–±–∞–≤–ª—è–π—Ç–µ –≤ –Ω–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ä–∞–±–æ—Ç—ã –¥–µ–∫–æ–¥–µ—Ä–∞ —Å $i$-—Ç–æ–π —Ü–∏—Ñ—Ä–æ–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuuU_kBc2AT6"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4GicWo32AT7"
      },
      "outputs": [],
      "source": [
        "plot_samples(*images)  # result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX-vmriu2AT7"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjkGD-az2AT7"
      },
      "source": [
        "–ü–µ—Ä–µ–Ω–µ—Å—Ç–∏ —Å—Ç–∏–ª–∏ —Ç—Ä–æ–µ–∫ –Ω–∞ –¥—Ä—É–≥–∏–µ —Ü–∏—Ñ—Ä—ã. –ü—Ä–∏ —ç—Ç–æ–º —Å–∞–º–∏ —Ç—Ä–æ–π–∫–∏ –¥–æ–ª–∂–Ω—ã –≤—ã–≤–µ—Å—Ç–∏—Å—å –∏—Å—Ö–æ–¥–Ω—ã–µ.\n",
        "\n",
        "–ü—Ä–∏–º–µ—Ä —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQiKqHJh2AT7"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/result_4_task_ex12.png\" width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW9sj1e22AT7"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ 5. –°–∏–∞–º—Å–∫–∞—è —Å–µ—Ç—å"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHgDTXh82AT7"
      },
      "source": [
        "–° –ø–æ–º–æ—â—å—é —Å–∏–∞–º—Å–∫–æ–π —Å–µ—Ç–∏ —Ä–µ—à–∏–º –∑–∞–¥–∞—á—É —Å Kaggle.\n",
        "\n",
        "–¶–µ–ª—å: –æ–±—É—á–∏—Ç—å —Å–∏–∞–º—Å–∫—É—é –º–æ–¥–µ–ª—å –æ—Ç–ª–∏—á–∞—Ç—å –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏.\n",
        "\n",
        "[[doc] üõ†Ô∏è Signature verification dataset (Kaggle)](https://www.kaggle.com/robinreni/signature-verification-dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJB9FE3j2AT8"
      },
      "source": [
        "<img src =\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/Exercises/EX12/signature_verification_dataset.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUGisXhv2AT8"
      },
      "source": [
        "–î–∞—Ç–∞—Å–µ—Ç —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–∞–±–æ—Ä–∞ —Å–∫–∞–Ω–æ–≤ –ø–æ–¥–ø–∏—Å–µ–π, —Ä–∞–∑–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø–æ –ø–∞–ø–∫–∞–º —Å–æ–≥–ª–∞—Å–Ω–æ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ:\n",
        "\n",
        "```\n",
        "sign_data_mini/\n",
        "‚îú‚îÄ‚îÄ train\n",
        "|   ‚îú‚îÄ‚îÄ 001\n",
        "|   |   ‚îú‚îÄ‚îÄ 001_01.PNG\n",
        "|   |   ‚îú ...\n",
        "|   |   ‚îî‚îÄ‚îÄ 001_24.PNG\n",
        "|   ‚îú‚îÄ‚îÄ 001_forg\n",
        "|   |   ‚îî‚îÄ‚îÄ ...\n",
        "|   ‚îú ...\n",
        "|   ‚îú‚îÄ‚îÄ 030\n",
        "|   |   ‚îî‚îÄ‚îÄ ...\n",
        "|   ‚îî‚îÄ‚îÄ 030_forg\n",
        "|       ‚îî‚îÄ‚îÄ ...\n",
        "‚îî‚îÄ‚îÄ test\n",
        "    ‚îú‚îÄ‚îÄ 049\n",
        "    |   ‚îî‚îÄ‚îÄ ...\n",
        "    |\n",
        "    ‚îú‚îÄ‚îÄ 049_forg\n",
        "    |   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îú ...\n",
        "    ‚îú‚îÄ‚îÄ 051\n",
        "    |   ‚îî‚îÄ‚îÄ ...\n",
        "    ‚îî‚îÄ‚îÄ 051_forg\n",
        "        ‚îî‚îÄ‚îÄ ...\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "–í –ø–∞–ø–∫–µ `id1` —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è —Å–∫–∞–Ω—ã –ø–æ–¥–ª–∏–Ω–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–µ–π –æ–¥–Ω–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞. –í –ø–∞–ø–∫–µ `id1_forg` —Å–æ–¥–µ—Ä–∂–∞—Ç—Å—è —Å–∫–∞–Ω—ã –ø–æ–¥–¥–µ–ª—å–Ω—ã—Ö –ø–æ–¥–ø–∏—Å–µ–π —Ç–æ–≥–æ –∂–µ —á–µ–ª–æ–≤–µ–∫–∞.\n",
        "\n",
        "–í –ø–∞–ø–∫–∞—Ö —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º `id2`, `id2_forg` ‚Äî –Ω–∞—Å—Ç–æ—è—â–∏–µ –∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ –¥—Ä—É–≥–æ–≥–æ —á–µ–ª–æ–≤–µ–∫–∞ –∏ —Ç. –¥.\n",
        "\n",
        "–í –ø–∞–ø–∫–µ `train` —Å–æ–±—Ä–∞–Ω—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ —Ç—Ä–∏–¥—Ü–∞—Ç–∏ —á–µ–ª–æ–≤–µ–∫ (`id = 001 ... 030`), –∞ –≤ –ø–∞–ø–∫–µ `test` ‚Äî –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏ —Ç—Ä–µ—Ö —á–µ–ª–æ–≤–µ–∫, –æ—Ç–ª–∏—á–Ω—ã—Ö –æ—Ç —Ç—Ä–∏–¥—Ü–∞—Ç–∏ \"–æ–±—É—á–∞—é—â–∏—Ö\" (`id = 049 ... 051`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_4CaZaM2AT8"
      },
      "source": [
        "–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∏–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvJgXiJW2AT8"
      },
      "outputs": [],
      "source": [
        "!pip install -q timm\n",
        "!pip install -q lightning\n",
        "!pip install -q torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7RLtEC22AT8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torchmetrics\n",
        "import pandas as pd\n",
        "import lightning as L\n",
        "import seaborn as sns\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from itertools import product\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn.functional import cosine_similarity\n",
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "from warnings import simplefilter\n",
        "\n",
        "simplefilter(\"ignore\", UserWarning)\n",
        "simplefilter(\"ignore\", RuntimeWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
      ],
      "metadata": {
        "id": "EvXfQIw3Agim"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEasrLir2AT8"
      },
      "source": [
        "–ó–∞–≥—Ä—É–∑–∏–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–π –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞–Ω–∏—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0b8g6nk2AT8"
      },
      "outputs": [],
      "source": [
        "!wget -qN https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/sign_mini.zip\n",
        "!unzip -qn sign_mini.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNRnIPqj2AT9"
      },
      "source": [
        "–ö–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–∞–Ω –≥–æ—Ç–æ–≤—ã–º.\n",
        "\n",
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –º–µ—Ç–æ–¥ `__getitem__` –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ –Ω–µ –∏–∑ –¥–≤—É—Ö, –∞ –∏–∑ —Ç—Ä–µ—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤:\n",
        "\n",
        "1. –†–µ–∞–ª—å–Ω–∞—è –ø–æ–¥–ø–∏—Å—å, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –∏–Ω–¥–µ–∫—Å—É `index`.\n",
        "2. –ü–æ–¥–ø–∏—Å—å, —Å –∫–æ—Ç–æ—Ä–æ–π –µ–µ –Ω—É–∂–Ω–æ —Å—Ä–∞–≤–Ω–∏—Ç—å. –° –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5 —ç—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥—Ä—É–≥–∞—è –Ω–∞—Å—Ç–æ—è—â–∞—è –ø–æ–¥–ø–∏—Å—å –∏ —Å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é 0.5 ‚Äî –ø–æ–¥–¥–µ–ª–∫–∞.\n",
        "3. –ú–µ—Ç–∫–∞, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è. –î–ª—è –¥–≤—É—Ö –Ω–∞—Å—Ç–æ—è—â–∏—Ö –ø–æ–¥–ø–∏—Å–µ–π —ç—Ç–æ $1$. –î–ª—è —Å–∏—Ç—É–∞—Ü–∏–∏, –∫–æ–≥–¥–∞ –æ–¥–Ω–∞ –∏–∑ –ø–æ–¥–ø–∏—Å–µ–π –ø–æ–¥–¥–µ–ª—å–Ω–∞—è, —ç—Ç–æ $-1$.\n",
        "\n",
        "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏–∑–º–µ–Ω—è—Ç—å —ç—Ç–æ—Ç –∫–ª–∞—Å—Å –Ω–µ—Ç, –æ–¥–Ω–∞–∫–æ —ç—Ç–æ –¥–æ–ø—É—Å—Ç–∏–º–æ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPqVctQt2AT9"
      },
      "outputs": [],
      "source": [
        "class SiameseNetworkDataset(Dataset):\n",
        "    def __init__(self, dir=None, transform=None):\n",
        "        self.dir = dir\n",
        "        self.transform = transform\n",
        "        self.classes = {1: \"Original\", -1: \"Forged\"}  # Change if need\n",
        "        self.data = self.get_pairs()\n",
        "        self.targets = self.get_targets()\n",
        "        self.cache = {}\n",
        "\n",
        "    def get_pairs(self):\n",
        "        pairs = []  # to store [orig, fake] or [orig, orig] pairs\n",
        "        persons = self.load_data()\n",
        "        for key in persons:\n",
        "            all_pairs = product(\n",
        "                persons[key][\"orig\"], persons[key][\"orig\"] + persons[key][\"forg\"]\n",
        "            )\n",
        "            # remove pairs with themselve\n",
        "            without_self_comparsion = list(filter(lambda x: x[0] != x[1], all_pairs))\n",
        "            pairs += without_self_comparsion\n",
        "        return pairs\n",
        "\n",
        "    def load_data(self):\n",
        "        all_paths = glob(f\"{self.dir}/**/*\")  # get all files path\n",
        "        persons = {}\n",
        "        # Group files by ID and type\n",
        "        for path in all_paths:\n",
        "            id, tp = SiameseNetworkDataset.parse(path)\n",
        "            if not id in persons:\n",
        "                persons[id] = {\"orig\": [], \"forg\": []}\n",
        "            persons[id][tp].append(path)\n",
        "        return persons\n",
        "\n",
        "    def get_targets(self):\n",
        "        targets = []\n",
        "        for pair in self.data:\n",
        "            _, tp = SiameseNetworkDataset.parse(pair[1])\n",
        "            label = -1 if tp == \"forg\" else 1\n",
        "            targets.append(label)\n",
        "        return targets\n",
        "\n",
        "    @staticmethod\n",
        "    def parse(path):\n",
        "        folder = path.split(os.sep)[-2]\n",
        "        id = folder.split(\"_\")[0]\n",
        "        tp = \"forg\" if \"forg\" in path else \"orig\"\n",
        "        return id, tp\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image1_path, image2_path = self.data[index]\n",
        "        labels = self.targets[index]\n",
        "\n",
        "        # Loading the images\n",
        "        image1 = self.load(image1_path)\n",
        "        image2 = self.load(image2_path)\n",
        "\n",
        "        return image1, image2, labels\n",
        "\n",
        "    def load(self, path):\n",
        "        if path in self.cache:\n",
        "            img = self.cache[path]\n",
        "        else:\n",
        "            img = Image.open(path).convert(\"L\")\n",
        "            self.cache[path] = img\n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2cje9Ro2AT9"
      },
      "source": [
        "–°–æ–∑–¥–∞–¥–∏–º —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5gkO4zn2AT9"
      },
      "outputs": [],
      "source": [
        "# Viewing the sample of images to check whether its loading properly\n",
        "print('\"1\" - real, \"-1\" - fake')\n",
        "\n",
        "vis_dataset = SiameseNetworkDataset(\n",
        "    \"/content/sign_data_mini/train\",\n",
        "    transform=transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((105, 105)),\n",
        "            transforms.ToTensor(),\n",
        "        ]\n",
        "    ),\n",
        ")\n",
        "\n",
        "vis_dataloader = DataLoader(vis_dataset, batch_size=8, shuffle=True)\n",
        "\n",
        "example_batch = next(iter(vis_dataloader))  # images1, images2, labels\n",
        "images1, images2, labels = example_batch\n",
        "# display the data\n",
        "concatenated = torch.cat((images1, images2), dim=0)\n",
        "grid = torchvision.utils.make_grid(concatenated)\n",
        "\n",
        "plt.figure(figsize=(20, 40))\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.imshow(grid.permute(1, 2, 0).numpy())\n",
        "plt.show()\n",
        "\n",
        "print(labels.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbexi1dP2AT9"
      },
      "source": [
        "–û—Ü–µ–Ω–∏–º –±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2lG3C2m2AT9"
      },
      "outputs": [],
      "source": [
        "# For check classes balance\n",
        "plt.hist(vis_dataset.targets)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## –°–æ–∑–¥–∞–Ω–∏–µ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –∏ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö"
      ],
      "metadata": {
        "id": "5HThF3zGCGX2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02m8_oXw2AT-"
      },
      "source": [
        "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç –∑–∞–≥—Ä—É–∑—á–∏–∫–æ–≤ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏, –∑–¥–µ—Å—å –≤ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è—Ö –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è.\n",
        "\n",
        "–≠—Ç–æ—Ç –±–ª–æ–∫ –º–æ–∂–Ω–æ –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5F5yFZj2AT-"
      },
      "outputs": [],
      "source": [
        "# Define transforms include Normalization\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize((105, 105)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(0.9409, 0.1078),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Load the dataset as pytorch tensors using dataloader\n",
        "sign_train_dataset = SiameseNetworkDataset(\n",
        "    dir=\"/content/sign_data_mini/train\", transform=transform\n",
        ")\n",
        "sign_train_loader = DataLoader(\n",
        "    sign_train_dataset, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "# Load the test dataset\n",
        "sign_test_dataset = SiameseNetworkDataset(\n",
        "    dir=\"/content/sign_data_mini/test\", transform=transform\n",
        ")\n",
        "sign_test_loader = DataLoader(\n",
        "    sign_test_dataset, batch_size=8, shuffle=False, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCvukboU2AT-"
      },
      "source": [
        "## –°–æ–∑–¥–∞–Ω–∏–µ —Å–µ—Ç–∏"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6DppkXN2AT-"
      },
      "source": [
        "–í –¥–∞–Ω–Ω–æ–º –±–ª–æ–∫–µ –Ω—É–∂–Ω–æ –æ–ø–∏—Å–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏.\n",
        "\n",
        "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –ø–æ—Å—Ç—É–ø–∞—é—Ç **–¥–≤–∞** –æ–¥–Ω–æ–∫–∞–Ω–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –∞ –Ω–µ –æ–¥–Ω–æ (–º–µ—Ç–æ–¥ `forward` –ø–æ–ª—É—á–∞–µ—Ç `input1` –∏ `input2`).\n",
        "\n",
        "–ù–∞ –≤—ã—Ö–æ–¥–µ **–¥–≤–∞** –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (embeddings) `out1` –∏ `out2`.\n",
        "\n",
        "–†–∞–∑–º–µ—Ä embedding –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ, –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 32‚Äì64 –∫–æ–º–ø–æ–Ω–µ–Ω—Ç.\n",
        "\n",
        "–î–æ–ø—É—Å–∫–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –æ—Å–Ω–æ–≤—ã –≥–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ torchvision –∏–ª–∏ timm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5AMm_t12AT-"
      },
      "outputs": [],
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, embedding_dim=32):\n",
        "        super().__init__()\n",
        "        # Your code here\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # Your code here\n",
        "        return out1, out2\n",
        "\n",
        "\n",
        "model = SiameseNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1OFlLc2AT-"
      },
      "source": [
        "## –ú–µ—Ç—Ä–∏–∫–∞"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCE6Hd3F2AT-"
      },
      "source": [
        "–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ `emb2pred` —Å–ª—É–∂–∏—Ç –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –º–µ–∂–¥—É –¥–≤—É–º—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –∏ –æ—Ç–Ω–µ—Å–µ–Ω–∏—è –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—ã –∫ –∫–ª–∞—Å—Å—É $0$ –∏–ª–∏ $1$ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ä–æ–≥–∞ `threshold`.\n",
        "\n",
        "–î–≤–µ –ø–æ–¥–ø–∏—Å–∏ —Å—á–∏—Ç–∞—é—Ç—Å—è –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—â–∏–º–∏ –æ–¥–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É, –µ—Å–ª–∏ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∏—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ –±–æ–ª—å—à–µ –ø–æ—Ä–æ–≥–∞. –ò–Ω–∞—á–µ –æ–¥–Ω–∞ –∏–∑ –ø–æ–¥–ø–∏—Å–µ–π —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–æ–¥–¥–µ–ª–∫–æ–π."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AH2VCrnO2AT_"
      },
      "outputs": [],
      "source": [
        "from torch.nn.functional import cosine_similarity\n",
        "\n",
        "\n",
        "def emb2pred(emb1, emb2, threshold):\n",
        "    sim = cosine_similarity(emb1, emb2)\n",
        "    pred = torch.empty_like(sim)\n",
        "    pred[sim < threshold] = 0  # Forged, not \"-1\" as in dataset for metric compute\n",
        "    pred[sim >= threshold] = 1  # Original\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHjuZmYB2AT_"
      },
      "source": [
        "–¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ —Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫—É –∫–∞—á–µ—Å—Ç–≤–∞. –í –∫–∞—á–µ—Å—Ç–≤–µ –º–µ—Ç—Ä–∏–∫–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è F1-score –∏–∑ torchmetrics. –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –Ω–∞ –Ω–µ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –æ–Ω–∞ –±—É–¥–µ—Ç –Ω–∏–∑–∫–æ–π.\n",
        "\n",
        "–î–ª—è –º–µ—Ç—Ä–∏–∫ –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –≤ torchmetrics –æ–∂–∏–¥–∞–µ—Ç—Å—è, —á—Ç–æ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤ –ø—Ä–∏–Ω–∞–¥–ª–µ–∂–∞—Ç $\\{0, 1\\}$. –ü–æ—ç—Ç–æ–º—É —Ñ—É–Ω–∫—Ü–∏—è `emb2pred` –≤—ã–¥–∞–µ—Ç $0$ –∏–ª–∏ $1$ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ—Ä–æ–≥–∞, –∞ –º–µ—Ç–∫–∏ $-1$ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∑–∞–º–µ–Ω—è—é—Ç—Å—è –Ω–∞ $0$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XY8dvv12AT_"
      },
      "outputs": [],
      "source": [
        "metric = torchmetrics.classification.BinaryF1Score()\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for batch in sign_test_loader:\n",
        "    images1, images2, labels = batch\n",
        "    emb1, emb2 = model(images1, images2)\n",
        "\n",
        "    preds = emb2pred(emb1, emb2, threshold=0.5)\n",
        "    labels[labels == -1] = 0  # for metric computation\n",
        "    metric.update(preds, labels)\n",
        "\n",
        "print(metric.compute().item())\n",
        "metric.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl2lNFZY2AT_"
      },
      "source": [
        "## –û–±—É—á–µ–Ω–∏–µ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpKe3RIT2AT_"
      },
      "source": [
        "–ë–ª–æ–∫ –∫–æ–¥–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –í –∫–∞—á–µ—Å—Ç–≤–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `torch.nn.CosineEmbeddingLoss` [üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html).\n",
        "\n",
        "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ —Ç–æ, —á—Ç–æ —ç—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å [–ø—Ä–∏–Ω–∏–º–∞–µ—Ç –ø—Ä–∏ —Ä–∞—Å—á–µ—Ç–µ üõ†Ô∏è[doc]](https://pytorch.org/docs/stable/generated/torch.nn.CosineEmbeddingLoss.html#:~:text=Default%3A%20%27mean%27-,Shape%3A,-Input1%3A):\n",
        "* –±–∞—Ç—á —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ‚Ññ1,\n",
        "* –±–∞—Ç—á —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ ‚Ññ2,\n",
        "* –±–∞—Ç—á –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤, —Å–æ—Å—Ç–æ—è—â–∏–π –∏–∑ $1$ –∏ $-1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ9g1eLv2AT_"
      },
      "outputs": [],
      "source": [
        "class LitSiamese(L.LightningModule):\n",
        "    def __init__(self, model, threshold=0.5):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.threshold = threshold\n",
        "\n",
        "        self.criterion =  # Your code here\n",
        "\n",
        "        self.train_metric = torchmetrics.classification.BinaryF1Score()\n",
        "        self.val_metric = torchmetrics.classification.BinaryF1Score()\n",
        "        self.test_metric = torchmetrics.classification.BinaryF1Score()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters())\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # 1. unpack batch\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "        # 2. do forward through model and loss, logging loss\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "        # 3. get {0, 1} predictions with self.threshold,\n",
        "        #    change \"-1\" labels to \"0\" and update train_metric\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def on_train_epoch_end(self):\n",
        "        # compute metric and do metric logging, reset train_metric\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # all the same steps as in training_step\n",
        "        # but without `return loss`\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        # all the same as in on_train_epoch_end\n",
        "\n",
        "\n",
        "    def on_test_epoch_start(self):\n",
        "        # initialise test results dict, nothing to change here\n",
        "        self.test_similarity_dict = {\"similarity\": [], \"true_label\": []}\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        # 1. unpack batch\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "        # 2. do forward through model\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "        # 3. accumulating test results dict in order to get similarity distributions\n",
        "        #    (nothing to change here)\n",
        "        cosine_sim = F.cosine_similarity(emb1, emb2)\n",
        "        for i in range(labels.shape[0]):\n",
        "            self.test_similarity_dict[\"similarity\"].append(cosine_sim[i].item())\n",
        "            self.test_similarity_dict[\"true_label\"].append(labels[i].item())\n",
        "\n",
        "        # 4. get {0, 1} predictions with self.threshold,\n",
        "        #    change \"-1\" labels to \"0\" and update test_metric\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        # compute and print test_metric value, reset test_metric\n",
        "        # Your code here\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # implement forward in lightning model to use it directly, nothing to change here\n",
        "        return self.model(input1, input2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYPbmtIK2AUA"
      },
      "source": [
        "–î–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö —ç–ø–æ—Ö–∞—Ö –∏ –¥–ª—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞ –∫ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è `ModelCheckpoint`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_uy9FF52AUA"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    save_last=False,\n",
        "    every_n_epochs=1,\n",
        "    save_top_k=-1,\n",
        "    save_weights_only=True,\n",
        "    monitor=\"val_f1\",\n",
        "    filename=\"model-{epoch}-{val_f1:.4f}\",\n",
        "    mode=\"max\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYw-C7ja2AUA"
      },
      "source": [
        "–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∑–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è. –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 3 —ç–ø–æ—Ö."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzo_Y03d2AUA"
      },
      "outputs": [],
      "source": [
        "from lightning.pytorch.loggers import TensorBoardLogger\n",
        "\n",
        "L.seed_everything(42)\n",
        "\n",
        "embedding_dim = 32\n",
        "pl_model = LitSiamese(SiameseNetwork(embedding_dim))\n",
        "\n",
        "logger = TensorBoardLogger(save_dir=\"lightning_logs\", name=\"task5_SiameseNetwork\")\n",
        "trainer = L.Trainer(\n",
        "    max_epochs=3, logger=logger, log_every_n_steps=1, callbacks=[checkpoint_callback]\n",
        ")\n",
        "\n",
        "trainer.fit(pl_model, sign_train_loader, sign_test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ktnao062AUA"
      },
      "source": [
        "## –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDWRQj5c2AUA"
      },
      "source": [
        "–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –∫–æ–¥ –¥–ª—è –≤—ã–≤–æ–¥–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgvLKsya2AUA"
      },
      "outputs": [],
      "source": [
        "def imshow(img, text=None):\n",
        "    npimg = (\n",
        "        img * 0.1078 + 0.9409\n",
        "    ).numpy()  # canceling transforms.Normalize(0.9409, 0.1078)\n",
        "    plt.figure(figsize=(5, 3))\n",
        "    plt.axis(\"off\")\n",
        "    plt.rcParams[\"figure.figsize\"] = (10, 20)\n",
        "    if text:\n",
        "        plt.text(\n",
        "            110,\n",
        "            8,\n",
        "            text,\n",
        "            style=\"italic\",\n",
        "            fontweight=\"bold\",\n",
        "            bbox={\"facecolor\": \"white\", \"alpha\": 0.8, \"pad\": 10},\n",
        "        )\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1n1vMAU2AUB"
      },
      "source": [
        "–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞ –æ–¥–Ω–æ–º –±–∞—Ç—á–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kwrB43z2AUB"
      },
      "outputs": [],
      "source": [
        "# Print the sample outputs to view its ssimilarity\n",
        "batch = next(iter(sign_test_loader))\n",
        "\n",
        "images1, images2, labels = batch\n",
        "emb1, emb2 = pl_model(images1, images2)\n",
        "\n",
        "cosine_sim = F.cosine_similarity(emb1, emb2)\n",
        "\n",
        "for i in range(labels.shape[0]):\n",
        "    concatenated = torch.cat((images1[i][0], images2[i][0]), 1)\n",
        "    label = sign_test_dataset.classes[labels[i].item()]\n",
        "    imshow(\n",
        "        torchvision.utils.make_grid(concatenated),\n",
        "        \"Cosine similarity: {:.2f} True label: {}\".format(\n",
        "            cosine_sim[i].item(),\n",
        "            label,\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    print(f\"Cosine similarity  {cosine_sim[i].item():.2f} (range [-1 .. 1])\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXa45FXk2AUB"
      },
      "source": [
        "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ (Cosine Similarity) –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è—Ö —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –≤ —Ä–∞–∑—Ä–µ–∑–µ –ø–æ –∏—Å—Ç–∏–Ω–Ω—ã–º –∫–ª–∞—Å—Å–∞–º.\n",
        "\n",
        "–î–ª—è —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å—Ç–∏–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏. –ü–æ—Å–ª–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —É –º–æ–¥–µ–ª–∏ –ø–æ—è–≤–∏—Ç—Å—è –∞—Ç—Ä–∏–±—É—Ç `.test_similarity_dict`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤–µ–ª–∏—á–∏–Ω—É –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –∏–∑ –ø–∞—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ, –∞ —Ç–∞–∫–∂–µ –º–µ—Ç–∫—É –∫–ª–∞—Å—Å–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–π –ø–∞—Ä—ã."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTr-gjjI2AUB"
      },
      "outputs": [],
      "source": [
        "trainer.test(dataloaders=sign_test_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc4hRNLI2AUC"
      },
      "source": [
        "–û—Ç–æ–±—Ä–∞–∑–∏–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–µ–π –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø–∞—Ä –≤ —Ä–∞–∑—Ä–µ–∑–µ –ø–æ –º–µ—Ç–∫–µ –∫–ª–∞—Å—Å–∞."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8h7D4nF2AUC"
      },
      "outputs": [],
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "test_results = pl_model.test_similarity_dict\n",
        "\n",
        "sim_df = pd.DataFrame(test_results)\n",
        "sim_df[\"label\"] = sim_df[\"true_label\"].map(sign_test_dataset.classes)\n",
        "display(sim_df)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.histplot(sim_df, x=\"similarity\", hue=\"label\", bins=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8Dbkgkj2AUC"
      },
      "source": [
        "–ö–∞–∫–æ–π –ø–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π —Å—Ö–æ–∂–µ—Å—Ç–∏ –ª—É—á—à–µ –≤—ã–±—Ä–∞—Ç—å, —á—Ç–æ–±—ã –æ—Ç–ª–∏—á–∞—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏ –ø–æ–¥–¥–µ–ª—å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∏?\n",
        "\n",
        "***Your text here***\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-byX8p_2AUC"
      },
      "source": [
        "–§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8e8pBee2AUC"
      },
      "outputs": [],
      "source": [
        "pl_model.threshold =  # Your value here\n",
        "trainer.test(dataloaders=sign_test_loader, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKsC9ky22AUD"
      },
      "source": [
        "## –§–æ—Ä–º–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
        "\n",
        "* –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–æ–¥ –æ–±—É—á–µ–Ω–∏—è —Å–∏–∞–º—Å–∫–æ–π —Å–µ—Ç–∏\n",
        "* –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è\n",
        "* –û—Ü–µ–Ω–∫–∞ –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏ –±–æ–ª—å—à–µ 0.8"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}